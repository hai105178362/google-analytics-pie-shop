# google-analytics-pie-shop
Google Analytics 、Google Optimize Example Site
节前AB测试思路

微店AB实验平台架构演进 https://segmentfault.com/a/1190000007559952

为什么建设AB测试平 
	1、每个产品线独立一套，或者压根就没有AB
	2、独立设计开发、维护
	3、支持少量规则
	4、实验缺乏严谨性
	5、大多使用配置上线


1. 统计严谨性：对系统及其产生的结果是否有信心？
如果平台实现得当，试验可以帮助团队快速确定哪些功能和变更能够成功推动业务的发展，哪些则相反。好的团队能够接受失败，并尽快重现并找出问题，以便为成功拓展出有效的想法。为了尽可能早的发现问题，团队需要相信AB测试试验被正确的创建和运行，并且试验结果也是准确的。

然而，许多公司低估了可靠收集数据和统计分析数据的难度。当事件未被正确的追踪，或者分析经常中止运行时，会导致试验速度下降和延迟。

在很多组织中，设置样本的大小与分析结果的责任通常归于数据分析团队。随着试验在多个团队中扩展，他们的进度逐渐成为瓶颈。

2. 易用性：系统对开发团队来说是否容易集成？对业务用户来说是否容易使用？
最好的团队每年都会进行数千次试验，以最大限度的提高学习机会。技术与非技术用户之间的可用性可能是一年中运行几个实验和成百上千个试验的差别。

在多数产品团队中，开发者需直接将测试集成在代码库中实现，因此他们通常会对AB测试解决方案的选择做初始决策。许多开源工具或自建系统在开始时整体在代码中运行，这意味着每次试验的最新变更都需要进行部署，并且在没有从数据库中抽取数据和没有亲自分析报告的条件下，产品经理或分析师很难理解运行中试验的状态。

确定系统是否为业务用户提供访问接口，系统是否包含远程配置工具和易于理解的操作界面。这些特性能够帮助团队将试验与部署分离，并提供跨组织的试验透明性，从而提升试验的速度。

在开发人员生产力方面，也应专注解决方案的功能，如多语言支持且内容详细的文档。这将让开发团队花费更少的时间来确定如何运行测试，并且有更多时间来处理面向客户的功能特性的工作上。一个强大的决策方案，应包括能够自动化执行特定任务，或者更深入的地集成到开发团队工作流程的API。

3. 总体成本：系统将如何开发，未来如何维护？	
	
谷歌把A/B测试研发出来，已经是2007年，2010年才公开发布了研究论文，此后才有第三方A/B测试的SaaS公司诞生。
A/B测试是一项非常基础的工作，海外的谷歌、微软，国内的BAT和字节跳动等公司都离不开A/B测试的辅助。单以字节公司为例，杨震原表示，A/B测试广泛应用于字节跳动方方面面，包括抖音和今日头条等产品命名、交互设计、推荐算法等。


[深度]A/B 测试中的因果推断——潜在结果模型

对 A/B测试有了解的读者都知道，A/B测试通过用户分组进行在线试验，可以对比产品两个版本的方案找出哪一个更好。但是很多人可能会问：我为什么一定要用 A/B Testing？Google Analytics 这么强大，我的产品的用户访问一目了然，通过数据分析不难找到问题所在，A/B测试还有必要吗？


在线对照实验 online controlled experiments
https://blog.analytics-toolkit.com/2017/statistical-significance-ab-testing-complete-guide/


“功能团队”（Feature Teams）已经可以在没有数据科学家的辅助下对大多数的实验进行独立的分析和运作。整个平台的专注点转移到了大规模自动化以及建立“机构记忆”上。同时通过对过去实验的分析，整个平台的有效性和针对实验运行的最佳实践也能够得到不断得更新。



（第3章）那就是利用“页面跳转”（Page Redirect）来实现针对“控制组”和“对照组”之间的分流。如果“控制组”不经过“页面跳转”而“对照组”经过“页面跳转”，这样的设计往往会带来两部分流量之间产生细微的但可以被检测出来的差别。从这个例子可以看出实验平台实现细节的重要性。

早期的实验平台都只支持“单层”（Single Layer）架构，意思就是100%的流量被分配到几个“流量桶”（Bucket）中。这些“流量桶”互相独立互不干涉。这样每个“流量桶”对应一个“对照组”（Treatment）。我们可以针对一系列“对照组”同时进行实验。然而，我们很容易发现，在这样的设置下单位时间内可以测试的“对照组”数目是有限的。因而，我们可能需要面临“流量”不够的情况。书中（第4章）介绍了“并发实验”（Concurrent Experiments）的概念，也就是“多层”（Multiple Layer）架构，可以允许多个实验同时在某一块流量上运行。当然，这虽然带来了理论上可以有无限流量的好处，但也为实验的分析提出了更高的要求。一般来说，我们需要能够分析两两实验之间的“交互”（Interaction）效果。成熟的实验平台需要能够支持“并发”实验以及能够检测实验之间的“交互”效果。




2012 年 Bing 的一个员工建议改进广告的显示方式， 将标题下的第一行合并到标题行， 形成一个长标题行。 改动如下:


在线控制实验在Airbnb等公司被大量使用，亚马逊，Booking.com，eBay，Facebook，谷歌，LinkedIn，Lyft，微软，Netflix，Twitter，Uber，Yahoo！/ Oath和Yandex。这些公司每年进行数千至数万次实验，有时涉及数百万用户并测试所有内容，包括更改到用户界面（UI）的相关算法（搜索，广告，个性化，
建议等），延迟/性能，内容管理系统，客户支持系统等。实验在多个平台上进行
渠道：网站，桌面应用程序，移动应用程序和电子邮件。

作者：ImWondering
链接：https://www.jianshu.com/p/4692bb3a3dda
来源：简书
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。


A/B测试，或随机对照实验，是因果推理的黄金标准方法——它们是证据阶梯的第一级！对于A/B测试，A组和B组是随机分配的。两组所处的环境是完全相同的，除了一个参数：他们看到的版本。随机性保证了两组都是 "平均 "的。这使你能够从A/B测试中推断出因果估计，因为它们唯一不同的是看到的版本，这样就可以判断到底是不是版本不同导致业务的变化。当然在实践中，有很多注意事项。

1、随机对照试验 (Randomized Controlled Trail)

随机对照试验更像是医学和生物学研究的说法，在互联网中更习惯叫 AB 测试。在实验中将用户随机分配到不同的实验组和控制组中，然后计算达到实验效果的样本量，实验到达到样本量的时候计算实验结果。因为随机性控制了其他干扰变量的影响，所以实验结果就是该实验因子对结果变量的真实影响大小。
